It is important to be grounded in the present, not in a metaphorical sense, but by admitting the limits of what current technology is able to provide us with. Even though highly specialized AIs have long surpassed human experts in narrow domains, they fail to generalize and often lack common sense, apart from countless other flaws previously discussed. Arguing that an AI, being better at a task than a human expert shows signs of real intelligence, is like saying wolfram alpha is a better mathematician than most humans.

Even Dreyfus could not have anticipated that AI scientists would realize their mistake, and give in to the valid arguments against symbolism by pursuing different paths. So he claimed that AI was impossible. However AI researchers commited the same fallacy by thinking that such programs were not necessary. Thinking that current approaches if only developed further would result in strong AI. Neither of them were correct. But both of them were necessary to surpass what has been.

Alan Turing once said, \textit{''We cannot so easily convince ourselves of the absence of complete laws of behaviour ... The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, We have searched enough. There are no such laws.''} \citelit{turing}. Arguing that we can create a mind is the same as arguing there has to be a god, or as arguing there cant be a god. Even though current approaches will certainly not surprise us with the sudden emergence of consciousness, this can not be mapped on the future.